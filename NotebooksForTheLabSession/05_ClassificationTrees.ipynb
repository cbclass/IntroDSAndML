{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Section 5: Classification Trees - Solution**\n",
    "\n",
    "Notebook for \"Introduction to Data Science and Machine Learning\"\n",
    "\n",
    "version 1.0, May 28 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use the relevant packages we need the following import statements: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Classification / Decision Tree: Self-Study Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a classification tree for the data of the self-study exercise:\n",
    "\n",
    "\n",
    "| X | Y | Z | C1 | C2|\n",
    "|-----|-----|-----|-----|----|\n",
    "|0|0|0|5|40|\n",
    "|0|0|1|0|15|\n",
    "|0|1|0|10|5|\n",
    "|0|1|1|45|0|\n",
    "|1|0|0|10|5|\n",
    "|1|0|1|25|0|\n",
    "|1|1|0|5|20|\n",
    "|1|1|1|0|15|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please load the data file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('data/classTreeExercise.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please call the command to look at the first lines of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please call the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to verify whether the data is consistent with the table of our exercise, we would prefer a different display. This can be achieved using the `groupby()` method (https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html#pandas.DataFrame.groupby).\n",
    "\n",
    "Please run the following code, check its output and compare it with the table of the exercise. Can you explain the output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.groupby([\"X\",\"Y\",\"Z\",'Class']).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create now two data frames: one with the features, i.e. the X, Y and Z values, and one with the target, the labels, that is the Class values. We use the following code. It should be familiar to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data=df.copy()# \n",
    "y_data=x_data.pop('Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the decision tree that is implemented in the class `DecisionTreeClassifier`. As with `MinMaxScaler` and `Regression`  we first must instantiate an object of the class and then use `fit()` to train / adapt the object.\n",
    "\n",
    "The method `fit()` of `MinMaxScaler` determines the minimum and maximum values of the data. The method `fit()` in  `Regression` learns the coefficient of the regression function using graient descent. `fit()` in the classification tree learns the tree. \n",
    "\n",
    "You find the documentation at https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "We can then use the classifier to classify new data. We can equally display it either as text or in a figure. In the following we will not only display the figures in the notebook but store them on the disk, so that you can download and open them as imagine and examine them in detail, as well as compare them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create a basic decision tree classifier. Without any further specification, this tree uses the Gini index to determine the best splitting criterion.\n",
    "\n",
    "$$GiniIndex=1-\\sum_{i=0}^{c-1}p_i(t)^2 $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classif = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And run it to classify our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classif = classif.fit(x_data, y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can display the decision tree as text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theTree=tree.export_text(classif)\n",
    "print(theTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can equally display the tree as a figure. In order to save the figure we need to create a figure object, that contains the displayed tree. With `dpi=600` (dots per inch) we set a reasonable resolution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig=plt.figure(dpi=600)\n",
    "tree.plot_tree(classif)# here we plot the tree\n",
    "fig.suptitle(\"Decision tree, version 1\") # this is the title for the figure\n",
    "fig.savefig('plots/tree1a.png') # and here we save it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The documentation for plotting is found here: https://scikit-learn.org/stable/modules/generated/sklearn.tree.plot_tree.html#sklearn.tree.plot_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tree is not so clear. E.g. we might not know what `X[0]` signifies. We can specify the feature names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(dpi=600)\n",
    "tree.plot_tree(classif,feature_names=[\"X\",\"Y\",\"Z\"])# here we plot the tree\n",
    "fig.suptitle(\"Decision tree, version 1 with feature names\") # this is the title for the figure\n",
    "fig.savefig('plots/tree1b.png') # and here we save it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As well as the class names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(dpi=600)\n",
    "tree.plot_tree(classif,feature_names=[\"X\",\"Y\",\"Z\"], class_names=['C1','C2'])# here we plot the tree\n",
    "fig.suptitle(\"Decision tree, version 1, feature and class names\") # this is the title for the figure\n",
    "fig.savefig('plots/tree1c.png') # and here we save it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And color the tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig=plt.figure(dpi=600)\n",
    "tree.plot_tree(classif,feature_names=[\"X\",\"Y\",\"Z\"], class_names=['C1','C2'], filled=True)# here we plot the tree\n",
    "fig.suptitle(\"Decision tree, version 1, names and colors\") # this is the title for the figure\n",
    "fig.savefig('plots/tree1d.png') # and here we save it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please look at above tree and explain the different colors and shades of the colors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now a \"beautiful\" decision tree. But we should not continue too fast. Please make sure to look carefully at the the tree and the information in all nodes. Please do not continue until you can explain all information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine the splitting of a node, we can use the Gini index.\n",
    "\n",
    "Another measure is the **Entropy** which is defined as\n",
    "$$-\\sum_{i=0}^{c-1}p_i(t) \\log_2 p_i(t)$$\n",
    "If we wish to use the entropy as a splitting criterion, we need to define a new classifier and specify the parameter `criterion`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifE = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "classifE = classifE.fit(x_data, y_data)\n",
    "fig=plt.figure(dpi=600)\n",
    "tree.plot_tree(classifE)# here we plot the tree\n",
    "fig.suptitle(\"Decision tree, version 2\") # this is the title for the figure\n",
    "fig.savefig('plots/tree2a.png') # and here we save it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please enhance the tree for the second classifier with class names, feature names as well as colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you see any differences when comparing the trees induced using Gini index and Entropy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Classification / Decision Tree: Classroom Assignment Example "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at the data set used in the classroom assignment. First we load the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../data/classTreeExercise2.csv')\n",
    "#df=pd.read_csv('data/classTreeExercise2.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we prepare the `X` data (features) and the `y` data (labels). We will use a version where `Customer ID` is part of the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data=df.copy()\n",
    "y_data=x_data.pop('Class')\n",
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the decision tree classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# induce the decision Tree (there will be an error, don't worry)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you will see an **error message** `ValueError: could not convert string to float: 'M'`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Data Preparation\n",
    "\n",
    "Now you will see an **error message** `ValueError: could not convert string to float: 'M'`.\n",
    "\n",
    "While the decision tree algorithm can handle nominal (catgorical or ordinal) data like the gender and shirt size in our example, the Python implementation of `DecisionTree` in `sklearn` **can't**.\n",
    "\n",
    "In order to use decision trees we need to convert all features to numbers.\n",
    "\n",
    "Of course we could devise an encoding by replacing each numerical feature by a number. But we should be careful by this! As we learned there are different data types. Categories do not imply an order while numbers imply orders.\n",
    "\n",
    "If a feature only has two values, like `Gender` we can replace it for such algorithms. In this case we might replace 'M' with 0 and 'F' with one. But we should be careful when we continue using the data later on, as 0 and 1 have an implicit order which gender does not have. There is no order among men and women!\n",
    "\n",
    "Now let's replace these values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use with to avoid the FutureWarning\n",
    "with pd.option_context('future.no_silent_downcasting', True):\n",
    "    x_data.replace({\"Gender\":{\"M\":0,\"F\":1}},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see that the data type of `Gender` was changed to int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the column `Shirt Size`. A shirt size has a clear order. We can use 1 for `Small` to 4 for `Extra Large` as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use with to avoid the FutureWarning\n",
    "with pd.option_context('future.no_silent_downcasting', True):\n",
    "    x_data.replace({\"Shirt Size\":{\"Small\":1,\"Medium\":2,\"Large\":3,\"Extra Large\":4}},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And check the types again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column `Car Type` has more than 2 values (it is not binary). If the types do not have an implicit order, i.e. are not ordinal, we should not impose such an order by replacing the categorical values with numbers. In this case we can use the so-called **one-hot-encoding**. With one-hot-encoding we create a separate column for each categorical value and assign values of 0 (the data record does not have this value) or 1 (the data record has this value) to it. The function `get_dummies()` in `pandas` creates a data set with a one-hot-encoder for all categorical columns:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data2=pd.get_dummies(x_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and compare it with the original data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Decision Tree Induction\n",
    "\n",
    "Now we can create a decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# induce the decicion Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(dpi=600)\n",
    "tree.plot_tree(classif2,feature_names=x_data2.columns,class_names=['C0','C1'], filled=True)# here we plot the tree\n",
    "fig.suptitle(\"Decision tree, Example 2, version 1, names and colors\") # this is the title for the figure\n",
    "fig.savefig('plots/treeEx2_1.png') # and here we save it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we have a decision tree that classifies our data perfectly! But it is based on `Customer ID`. As discussed in the lecture, the attribute `Customer ID` should not be used for the split even if the attribute test condition has the lowest value.\n",
    "\n",
    "Therefore we will remove the attribute from the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data2.pop('Customer ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classif2=tree.DecisionTreeClassifier()\n",
    "classif2.fit(x_data2,y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig=plt.figure(dpi=600)\n",
    "tree.plot_tree(classif2,feature_names=x_data2.columns,class_names=['C0','C1'], filled=True)# here we plot the tree\n",
    "fig.suptitle(\"Decision tree, Example 2, version 1, names and colors\") # this is the title for the figure\n",
    "fig.savefig('plots/treeEx2_2.png') # and here we save it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see, that above tree looks different from the tree we would have constructed in the lecture. Based on the calculated values we would use as first splitting criterion `Gender`. In the classroom assessment we determined the Gini Index for a multiway split. `DecisionTreeClassifier` in `sklearn` always uses a binary split for numerical values. As all Sports-cars belong to class C0, the attribute `Sports` leads to the best split on the first level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Classification / Decision Tree: Breast Cancer data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now derive a decision tree for the Breast Cancer data set that is often used as an example for machine learning: https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-wisconsin-diagnostic-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to load the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer=load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that `cancer` is a data set and not a data frame. It has among others the following elements: \n",
    "- `cancer.data` : the data in form of a matrix\n",
    "- `cancer.feature_names` : the names of the attributes as a list\n",
    "- `cancer.target` : the labels\n",
    "- `cancer.target_names` : the values of the class labels\n",
    "\n",
    "Plese use the following cell to look at this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`X` is our data, `y` is our target. We create a decision tree and fit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=cancer.data, cancer.target\n",
    "classif = tree.DecisionTreeClassifier()\n",
    "classif = classif.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We output the data as text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the feature_names array is not accepted for the function, therefore I use Liste comprehension\n",
    "# in the following line of code, to translate the array to a list of strings\n",
    "names=[i for i in cancer.feature_names]\n",
    "theTree=tree.export_text(classif,feature_names=names) # translate the tree to a set of rules\n",
    "print(theTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can display the tree in a figure:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(dpi=600)\n",
    "tree.plot_tree(classif,feature_names=cancer.feature_names)\n",
    "fig.suptitle('Cancer Data Set')\n",
    "fig.savefig('plots/cancer1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is difficult to read the tree. But when you open the graphics on the disk, you can easily zoom in and explore the tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now output the accuracy of the decision tree with `score()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classif.score(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect accuracy! Wow!\n",
    "\n",
    "But is this realistic? **No!** There is something wrong. When we look at the leaves in the tree, there is no impurity. The Gini index in all leaves is 0. We achieved a minimum **bias**, i.e. minimum training errors. But the score is calculated on the same data. That is, we have no idea how well the tree can classify data it has not seen before.\n",
    "\n",
    "Therefore we now split our data in two sets. A test set, containing 33% of the data as well as a training set, with the remaining data. We will derive a classifcation tree based on the training data and then see how well it performs on the (so far unseen) test data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the method `train_test_split()` to split the data in trainings and test data. The method receives `X` and `Y` as paramaters. Optional parameters allow for the specification of the size of the two sets. One optional paramater `random_state` allows for specifying a reproducable state of the random number generator, as the splitting is controlled by random numbers. When setting the state of the random number generator, the same sequence of random numbers can be reproduced and, thus, \"experiments\" repeated.\n",
    "\n",
    "The split is produced in the following line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.33, random_state=33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now train a new model using the training data `X_train` and `y_train`. To allow for reproducability we equally set the `random_state` in the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classif2 = tree.DecisionTreeClassifier(random_state=33)\n",
    "classif2 = classif2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we plot the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(dpi=600)\n",
    "tree.plot_tree(classif2,feature_names=cancer.feature_names)\n",
    "fig.suptitle('Cancer Data Set')\n",
    "fig.savefig('plots/cancer2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to determine the accuracy we use the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"accuracy classif2:\",classif2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before all leaves in the decision tree have an impurity of 0, i.e. the Gini index is 0. We equally observe that the accuracy is less than 100%, which makes sense as the testing data has not been seen before. This accuracy value now refers to the **variance**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to determine the **confusion matrix** we need to predict the classes for the test data (`test_X`). To do so we use the method `predict()` of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict=classif2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And compute the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test,y_predict)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrix is an `numpy` array and we can access its individual elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('False negatives:',cm[0,1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We can also make a more beautiful matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=['WDBC-Malignant','WDBC-Benign'])\n",
    "cmd.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier can be specified using different parameters. These can influence the variance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classif3 = tree.DecisionTreeClassifier( min_samples_leaf=3, max_depth=4, max_features=8,random_state=33)\n",
    "classif3 = classif3.fit(X_train, y_train)\n",
    "y_predict=classif3.predict(X_test)\n",
    "cm2=confusion_matrix(y_test,y_predict)\n",
    "print('accuracy classif3:',classif3.score(X_test, y_test))\n",
    "print(cm2)\n",
    "cmd = ConfusionMatrixDisplay(cm2, display_labels=['WDBC-Malignant','WDBC-Benign'])\n",
    "cmd.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the documentation https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html to understand the different parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the function `error_measures()` for `cm2` and compare the results.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exercise\n",
    "\n",
    "Load the penguins data set and induce a decision tree to predict the species.\n",
    "\n",
    "Please note that decision tree classifers do not accept input with `nan` values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "penguins=sns.load_dataset('penguins')\n",
    "\n",
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*End of the Notebooks*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-nd/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png\" /></a><br />This notebook was created by Christina B. Class for teaching at EAH Jena and is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-nd/4.0/\">Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e1e76f8",
   "metadata": {},
   "source": [
    "**Section 4: Linear Regression**\n",
    "\n",
    "Notebook for \"Introduction to Data Science and Machine Learning\"\n",
    "\n",
    "version 1.0, May 27 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e81f40",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f106c586",
   "metadata": {},
   "source": [
    "In this lab we will use functions and carry out a linear regression task. \n",
    "\n",
    "We need the following modules. So please run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc3fb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4710a0e1",
   "metadata": {},
   "source": [
    "## 1. Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee4601c",
   "metadata": {},
   "source": [
    "We load the dataset. We will use one of the data sets that is often recommended for classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c332f46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('data/winequality-red.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e6c7e9",
   "metadata": {},
   "source": [
    "## 2. Getting to know the data\n",
    "\n",
    "Use code you used in former lab assignments:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974bd8b4",
   "metadata": {},
   "source": [
    "- Display the first five rows of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a077ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799a70f4",
   "metadata": {},
   "source": [
    "- Display the information about the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eefefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62332a2d",
   "metadata": {},
   "source": [
    "- Display the statistical information of the numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c98799",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# your code\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef78d27e",
   "metadata": {},
   "source": [
    "## 3. Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff33c71",
   "metadata": {},
   "source": [
    "As we could see above there are no null values. We should now check for duplicate entries. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da711db2-f81d-4910-9352-75bda6c43ce4",
   "metadata": {},
   "source": [
    "Lets count how many duplicated rows are in the data set. `duplicated()` returns a boolean series denoting duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ce0f2a-6e74-4bf8-930f-c9c6034473ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Number of duplicates\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc159d3e-2187-4f8b-b934-90fd20d079d3",
   "metadata": {},
   "source": [
    "We use `inplace=True` in `drop_duplicates()` to modify the data by removing the duplicates, i.e. we modify the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138a50c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the duplicates in the original data\n",
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e605cf",
   "metadata": {},
   "source": [
    "## 4. Data Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4bd3e1",
   "metadata": {},
   "source": [
    "In machine learning we normally split our data into several sets. The easiest split is splitting the data into 2 sets, the *training* and the *test* set. Data in the training set is used to learn a model (here the linear regression). We then use the test set data (that is unknown to the model) to estimate how good the model is. We will look at this in the lecture. \n",
    "\n",
    "We use the function `train_test_split()` to create random trainings and test subsets.\n",
    "\n",
    "Often the data is split in 70% trainings and 30% test data.\n",
    "\n",
    "Using `random_state` we get reproducible splits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce314401-e72c-4227-b699-86e568470d9a",
   "metadata": {},
   "source": [
    "Before we split the data, we take a look at the `quality` attribute. Contrary to the other atrributes it is of type `int32` with few unique values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a204b655-c5a3-41d1-a6e1-d209e24f8ba3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.quality.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9dce48-a726-4ae7-9295-6c22e6ef3fc6",
   "metadata": {},
   "source": [
    "The `quality` can be seen as target variable / class. We will not use it in the regression task and thus drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57538918-1f5e-4c65-81bc-93ae0f4b07c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "regressionData=data.drop(columns=['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1a804d-4348-484c-9161-e21ae150daae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "regressionData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6678ed0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dfTrain, dfTest=train_test_split(regressionData,train_size=0.7,test_size=0.3,random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e06d2aa",
   "metadata": {},
   "source": [
    "Let's take a look at the data set sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc99dcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('training set:',dfTrain.shape[0])\n",
    "print('test set:',dfTest.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e90e7b",
   "metadata": {},
   "source": [
    "Let's plot the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef228ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(dfTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717e384e",
   "metadata": {},
   "source": [
    "And the correlation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a197d49c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.heatmap(data.corr(),cmap='RdBu') # with annot=True the values will be displayed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a604514",
   "metadata": {},
   "source": [
    "## 5. Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405d915a",
   "metadata": {},
   "source": [
    "As the range of the values of the features are different we apply scaling. We use the `MinMaxScaler` to perform scaling to the interval $[0,1]$. \n",
    "\n",
    "**Important:** It is important that the training, i.e. the development of the regression model, is completely **independent** of the test data. Therefore the scaling must only base on the trainings data. It is thus performed after splitting the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb00bec",
   "metadata": {},
   "source": [
    "We use the `MinMaxScaler` of `scikit-learn` to perform the scaling. `MinMaxScaler` is a class. We first create a so-called instance of this class, an object, and then we use the object to perform the scaling. The following code shows one example how to apply the `MinMaxScaler`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376111c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the class\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# instantiate (=create) a MinMaxScaler object with default characteristics\n",
    "theScaler=MinMaxScaler()\n",
    "\n",
    "# determine minimum and maximum to be used for scaling (initialize the scaler for the data)\n",
    "theScaler.fit(dfTrain)\n",
    "\n",
    "# scale the data to [0,1] and store it in a numpy array\n",
    "dfTrainScaled=theScaler.transform(dfTrain)\n",
    "\n",
    "# scale the data to [0,1] and replace the values in the data frame \n",
    "dfTrain[:]=theScaler.transform(dfTrain[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0cc7b9",
   "metadata": {},
   "source": [
    "`dfTrainScaled` is a `numpy` array while `dfTrain` is still a data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a73ebb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(dfTrainScaled),type(dfTrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47918683",
   "metadata": {},
   "source": [
    "Please display the statistical information of `dfTrain`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08126434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227b9659-0637-458e-8efb-efba379cdcd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfTrain.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939c0e8f-a385-4f5d-9044-755a0e35b6fb",
   "metadata": {},
   "source": [
    "Now we apply the same scaler model to the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957f44f8-293b-431d-a78b-49a97a4cc635",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# scale the data to [0,1] and replace the values in the data frame \n",
    "dfTest[:]=theScaler.transform(dfTest[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a69ec8b-9d66-4640-9017-ce7be0e840c6",
   "metadata": {},
   "source": [
    "Now let's take a look at the minimum and maximum values of the columns in the testing and the trainigs data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bca1172-b4f3-4dfd-ae1e-8594760351a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "minMaxDf=pd.DataFrame([dfTest.min(),dfTrain.min(),dfTest.max(),dfTrain.max()], \n",
    "                      index=[\"test min\",\"train min\", \"test max\",\"train max\"]).T \n",
    "\n",
    "minMaxDf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebabd80-ca0b-406a-9c02-6764bb1861a7",
   "metadata": {},
   "source": [
    "**Question:** Can you explain the values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c41171",
   "metadata": {},
   "source": [
    "## 6. Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6472ebd5",
   "metadata": {},
   "source": [
    "The columns of the data frame are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326f91af",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrain.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f27166",
   "metadata": {},
   "source": [
    "We will build a model for `citric acid`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5f8725",
   "metadata": {},
   "source": [
    "We first create the `X` and `y` data from `dfTrain`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2835f771",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# copy the data frame to a new one\n",
    "XTrain=dfTrain\n",
    "\n",
    "# remove the column 'citric acid' from the data frame and store it in a new variable\n",
    "yTrain=XTrain.pop('citric acid')\n",
    "\n",
    "print('shape XTrain',XTrain.shape)\n",
    "print('shape yTrain',yTrain.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e296ad09",
   "metadata": {},
   "source": [
    "We now build a linear regression model using the class `LinearRegression` in the module `sklearn.linear_model`. As with the `MinMaxScaler` we need to create an instance first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f70a5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the class\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# instantiate the class, create a regression model\n",
    "lm=LinearRegression()\n",
    "\n",
    "# train the model\n",
    "lm.fit(XTrain,yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a41951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the names of the features seen during the training\n",
    "lm.feature_names_in_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2974a51a",
   "metadata": {},
   "source": [
    "Now we can display the coefficients that were learned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e2fe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7be994",
   "metadata": {},
   "source": [
    "We now use the model to predict data. First we need to remove the `citric acid` column from the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3728838c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the data frame to a new one\n",
    "XTest=dfTest\n",
    "\n",
    "# remove the column 'citric acid' from the data frame and store it in a new variable\n",
    "yTest=XTest.pop('citric acid')\n",
    "\n",
    "print('shape Xtest',XTest.shape)\n",
    "print('shape yTest',yTest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d34735",
   "metadata": {},
   "source": [
    "And now we use the model to predict the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3de67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "yPredicted=lm.predict(XTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2996fe5",
   "metadata": {},
   "source": [
    "And now we can calculate the error and plot them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309830de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "errors=yTest-yPredicted\n",
    "\n",
    "plt.boxplot(errors,vert=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b222867",
   "metadata": {},
   "source": [
    "We can also plot the differences in a scatter plot. As we have a multivariate linear regression, we cannot plot all variables. On the $x$-axis we thus simply plot the number of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2927f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "xNumbers=list(range(1,len(yTest)+1))\n",
    "plt.plot(xNumbers,yTest,'.',label='the data')\n",
    "plt.plot(xNumbers,yPredicted,'.',label='predicted')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2e1499",
   "metadata": {},
   "source": [
    "In fact, the model is not very good. Let's take a look at the statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e033135",
   "metadata": {},
   "source": [
    "## 7. Statistics of Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cbf086",
   "metadata": {},
   "source": [
    "In order to take a look at the statistics of the regression we build the model using the `statsmodels.api`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3c1c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3999d271",
   "metadata": {},
   "source": [
    "First we add the constant ($x_0$ that is always 1) as an additional feature for the multivariate regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b308a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the data frame\n",
    "XTrainDF=XTrain.copy()\n",
    "# add the constant\n",
    "XTrainDF = sm.add_constant(XTrainDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f84bf4c",
   "metadata": {},
   "source": [
    "Then we train the model using ordinary least square:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66869504",
   "metadata": {},
   "outputs": [],
   "source": [
    "smLm = sm.OLS(yTrain,XTrainDF).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46815253",
   "metadata": {},
   "source": [
    "And we display the statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b38e59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(smLm.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0793cf33",
   "metadata": {},
   "source": [
    "In above table we see the $R^2$ value of 0.690. The adjusted $R^2$ value is 0.687. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945a767e",
   "metadata": {},
   "source": [
    "You might remember that some variables might improve the result of linear regression by chance. Therefore $R^2$ is corrected.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f34f29",
   "metadata": {},
   "source": [
    "## 8. Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7c3649",
   "metadata": {},
   "source": [
    "Above model bases on 10 features. \n",
    "\n",
    "Let's try to reduce the number of features: Let's try a model with 8 features. Of course we should not simply select any eight features but the ones that are most important for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a435e72d",
   "metadata": {},
   "source": [
    "We use the class `RFE`(recursive feature elimination) in the module `sklearn.feature_selection`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07ed837",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b93db62",
   "metadata": {},
   "source": [
    "Now we instantiate the class using the linear regression model we build and asking for $n$ the most important features. Let's look for the 8 most important features: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12fba06",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe=RFE(lm,n_features_to_select=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8324d798",
   "metadata": {},
   "source": [
    "And now we applt this estimator object to our trainings data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4835994",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfeObj=rfe.fit(XTrainDF, yTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0775e76",
   "metadata": {},
   "source": [
    "And we display the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1809c9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{:22} {:7} {:2}\".format(\"column\",\"support\",\"rank\"))\n",
    "for el in list(zip(XTrainDF.columns,rfeObj.support_,rfeObj.ranking_)):\n",
    "    print(f\"{el[0]:22} {str(el[1]):7} {el[2]:2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4282536",
   "metadata": {},
   "source": [
    "We display the support as well as the ranking. The 8 most important features are ranked with 1 and have a support of `True`. We use now this support to reduce the features to the most relevant 8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a8f90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrainDF2=XTrainDF[XTrainDF.columns[rfe.support_]]\n",
    "\n",
    "print(XTrainDF2.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b226db",
   "metadata": {},
   "source": [
    "The features might equally have been reduced using `XTrainDF3=rfeObj.transform(XTrainDF)`. The result in this case would be a `numpy` array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c585ac9",
   "metadata": {},
   "source": [
    "Now we can relearn the model and calculate the new statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167ab03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrainDF2 = sm.add_constant(XTrainDF2)\n",
    "smLm2 = sm.OLS(yTrain,XTrainDF2).fit()\n",
    "print(smLm2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c4f1ad-3e23-4276-9ad3-be094b88987a",
   "metadata": {},
   "source": [
    "Our model has the same $R^2$ values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21892bbc",
   "metadata": {},
   "source": [
    "## 9.Variance Inflation Factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f7ce58",
   "metadata": {},
   "source": [
    "When we reduce feature we try to identify the most important ones. If two features have a high linear correlation the model becomes complex and very hard to be interpreted. Therefore, it is sometimes advisable to eliminate one of the features. The `variance_inflation_factor` helps identifying such features:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ed6c94",
   "metadata": {},
   "source": [
    "First, we import the required class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffa8fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54a3c6c",
   "metadata": {},
   "source": [
    "Then we create a data frame with:\n",
    "- the column names\n",
    "- the variance inflation factor for the columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50720a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the VIF values\n",
    "vifList=[]\n",
    "dfAsNumpy=XTrainDF2.values\n",
    "# for all columns\n",
    "for c in range(XTrainDF2.shape[1]):\n",
    "    vifList.append(variance_inflation_factor(dfAsNumpy,c))\n",
    "vifArray=np.array(vifList)\n",
    "vifArray=vifArray.round(2)\n",
    "\n",
    "# create an empty data frame\n",
    "vif = pd.DataFrame()\n",
    "\n",
    "# create a column features with column names    \n",
    "vif['Features'] = XTrainDF2.columns\n",
    "# create a column VIF with the calculated values\n",
    "vif['VIF']=vifArray\n",
    "# sort the data frame in descending order\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "\n",
    "print(vif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eced5f48",
   "metadata": {},
   "source": [
    "It is recommended to eliminate any feature with an VIF larger than 5 (https://www.statsmodels.org/stable/generated/statsmodels.stats.outliers_influence.variance_inflation_factor.html#). We do not have such a feature (remember that const is the intercept)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92165b44",
   "metadata": {},
   "source": [
    "## 10. Exercise\n",
    "\n",
    "Repeat the steps in section 6 ff. to create a regression model for `residual sugar`. Do you get better results? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecfc97b-297b-4bcd-a79d-4affbb34ce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2526119",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-nd/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png\" /></a><br />This notebook was created by Christina B. Class for teaching at EAH Jena and is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-nd/4.0/\">Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
